{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from eval import eval_net\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.dataset import BasicDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils.dice_loss import SoftDiceLoss\n",
    "import torch.backends.cudnn\n",
    "from unet.dinknet import DinkNet101 as DlinkNet101\n",
    "from test import test_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dir_img = 'data/cropped_cz_src/'\n",
    "dir_mask = 'data/cropped_cz_mask/'\n",
    "\n",
    "\n",
    "def tst_net(net,\n",
    "              device,\n",
    "              batch_size=1,\n",
    "              img_scale=0.5):\n",
    "\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "    tst_size = len(dataset)\n",
    "    tst_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=True)\n",
    "    dataset.aug = False\n",
    "\n",
    "    writer = SummaryWriter(comment=f'BS_{batch_size}_SCALE_{img_scale}_TEST_RUN')\n",
    "    global_step = 0\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Batch size:      {batch_size}\n",
    "        Test size        {tst_size}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "    ''')\n",
    "\n",
    "    tst_score, imgs, masks_pred, true_masks = test_net(net, tst_loader, device)\n",
    "\n",
    "    if net.n_classes > 1:\n",
    "        logging.info('Validation cross entropy: {}'.format(tst_score))\n",
    "        writer.add_scalar('Loss/test', tst_score, global_step)\n",
    "    else:\n",
    "\n",
    "        logging.info('Validation Dice Coeff: {}'.format(tst_score))\n",
    "        writer.add_scalar('Dice/test', tst_score, global_step)\n",
    "\n",
    "    writer.add_images('images', imgs, global_step)\n",
    "    if net.n_classes == 1:\n",
    "        writer.add_images('masks/true', true_masks, global_step)\n",
    "        writer.add_images('masks/pred', masks_pred > 0.5, global_step)\n",
    "\n",
    "    writer.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cpu\n",
      "INFO: Network:\n",
      "\t3 input channels\n",
      "\t1 output channels (classes)\n",
      "\n",
      "INFO: Model loaded from C:\\Users\\Tim Wang\\Desktop\\gitclone\\XiyuUnderGradThesis\\checkpoints\\CP_epoch8.pth\n",
      "INFO: Creating dataset with 1935 examples\n",
      "INFO: Starting training:\n",
      "        Batch size:      4\n",
      "        Test size        1935\n",
      "        Device:          cpu\n",
      "        Images scaling:  1\n",
      "    \n",
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "batchsize = 4\n",
    "scale = 1\n",
    "load_dir = r'C:\\Users\\Tim Wang\\Desktop\\gitclone\\XiyuUnderGradThesis\\checkpoints\\CP_epoch8.pth'\n",
    "device = torch.device('cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "net = DlinkNet101(num_classes=1, num_channels=3)\n",
    "logging.info(f'Network:\\n'\n",
    "             f'\\t{net.n_channels} input channels\\n'\n",
    "             f'\\t{net.n_classes} output channels (classes)\\n')\n",
    "\n",
    "if load_dir:\n",
    "    net.load_state_dict(\n",
    "        torch.load(load_dir, map_location=device)\n",
    "    )\n",
    "    logging.info(f'Model loaded from {load_dir}')\n",
    "\n",
    "net.to(device=device)\n",
    "# faster convolutions, but more memory\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "try:\n",
    "    tst_net(net=net,\n",
    "            batch_size=batchsize,\n",
    "            device=device,\n",
    "            img_scale=scale,)\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    try:\n",
    "        sys.exit(0)\n",
    "    except SystemExit:\n",
    "        os._exit(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}